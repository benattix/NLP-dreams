{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "from random import shuffle\n",
    "import xmltodict\n",
    "import json\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# view all columns of pandas df\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# nltk.download('wordnet')      # download wordnet if it's not already downloaded\n",
    "\n",
    "with open (\"dreambank-public.xml\") as f:\n",
    "    doc = xmltodict.parse(f.read())\n",
    "\n",
    "def convert(data):\n",
    "    if isinstance(data, basestring):\n",
    "        return str(data)\n",
    "    elif isinstance(data, collections.Mapping):\n",
    "        return dict(map(convert, data.iteritems()))\n",
    "    elif isinstance(data, collections.Iterable):\n",
    "        return type(data)(map(convert, data))\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def left(s, amount):\n",
    "    return s[:amount]\n",
    "\n",
    "def right(s, amount):\n",
    "    return s[-amount:]\n",
    "\n",
    "def mid(s, offset, amount):\n",
    "    return s[offset:offset+amount]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "First we want to print the data to see which fields we are given and how the data looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dreamer in doc['dreambank']['collection']:\n",
    "    print dreamer['name'] + ' (' + str(len(dreamer['dream'][:])) + ' dreams)' \n",
    "    print '  ID: ' + dreamer['id']\n",
    "    print '  type: ' + dreamer['type']\n",
    "    print '  sex: ' + dreamer['sex']\n",
    "    print '  age: ' + dreamer['age']\n",
    "    \n",
    "    try:\n",
    "        print '  time: ' + dreamer['time']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print '  sample dream: ' \n",
    "    \n",
    "    odict = dreamer['dream'][0]\n",
    "    for key, value in odict.items():\n",
    "        if convert(key) == 'report':\n",
    "            print '    report: ' + left(convert(value), 200) + '...'\n",
    "        else:\n",
    "            print '    ' + convert(key) + ': ' + str(convert(value))\n",
    "        \n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print '---Dream collections from individuals---' + '\\n'\n",
    "MultIDs = ['b', 'madeline1-hs', 'madeline2-dorms', 'madeline3-offcampus', 'phil1', 'phil2', 'vietnam_vet']\n",
    "NumberOfSeries = 1\n",
    "\n",
    "for dreamer in doc['dreambank']['collection']:\n",
    "    if dreamer['type'] == 'series':\n",
    "        print '{' + dreamer['id']  + '} ' + dreamer['name'] + ' (' + str(len(dreamer['dream'][:])) + ' dreams)' + ' [' + dreamer['sex'] + ']'    \n",
    "        dreamer['w266ID'] = NumberOfSeries\n",
    "        \n",
    "        # Assign a dreamer ID that groups the same dreamers together \n",
    "        # and skips the dream collections of multiple dreamers\n",
    "        print 'w266 ID: ' + str(dreamer['w266ID'])\n",
    "        if dreamer['id'] not in MultIDs:\n",
    "            print '\\n'\n",
    "            NumberOfSeries += 1\n",
    "    else:\n",
    "        dreamer['w266ID'] = 0\n",
    "        \n",
    "print \"Total Number of individuals to test vs. 'others': \" + str(NumberOfSeries - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DreamNum = 0\n",
    "\n",
    "for dreamer in doc['dreambank']['collection']:\n",
    "    for odict in dreamer['dream']:\n",
    "        for key, value in odict.items():            \n",
    "            if convert(key) == 'report':\n",
    "                DreamNum += 1\n",
    "\n",
    "print \"Total Dreams: \" + str(DreamNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA - Reduce To Noun-Only And Lemmatize\n",
    "\n",
    "For our topic modeling, we will want to lemmatize the corpus and reduce to nouns-only. However, before we get to topic modeling, it will be helpful to test out the lemmatization and noun-only reduction techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to noun-only and lemmatize\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "for dreamer in doc['dreambank']['collection']:\n",
    "    print dreamer['name'] + ' (' + str(len(dreamer['dream'][:])) + ' dreams)' + ' [' + dreamer['sex'] + ']'\n",
    "    \n",
    "    print '  noun-only sample dream: ' \n",
    "    \n",
    "    odict = dreamer['dream'][0]\n",
    "    \n",
    "    # (1) tokenize dream text\n",
    "    # (2) tag with PoS\n",
    "    # (3) reduce to noun-only\n",
    "    # (4) lemmatize nouns\n",
    "    # (5) get frequency counts of the lemmatized nouns\n",
    "    for key, value in odict.items():\n",
    "        if convert(key) == 'report':\n",
    "            text = nltk.tokenize.word_tokenize(value)\n",
    "            pos = nltk.pos_tag(text)\n",
    "            noun_only = [w[0] for w in pos if w[1].startswith('N')]\n",
    "            lmtz_noun_only = [lmtzr.lemmatize(word) for word in noun_only]\n",
    "            counts = Counter(lmtz_noun_only)\n",
    "            print counts\n",
    "        \n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 0\n",
    "W266ID = 0\n",
    "DreamBankID = ''\n",
    "DreamNumber = ''\n",
    "Name = ''\n",
    "Sex = ''\n",
    "Dream = ''\n",
    "HasDream = 0\n",
    "\n",
    "df = pd.DataFrame(columns=[\"ID\", \"W266ID\", \"DreamBankID\", \"DreamNumber\", \"Name\", \"Sex\", \"Dream\"])\n",
    "\n",
    "for dreamer in doc['dreambank']['collection']:\n",
    "    Name = dreamer['name'] \n",
    "    DreamBankID = dreamer['id']\n",
    "    W266ID = int(dreamer['w266ID'])\n",
    "    Sex = dreamer['sex']\n",
    "    \n",
    "    for odict in dreamer['dream']:\n",
    "        HasDream = 0\n",
    "        for key, value in odict.items():\n",
    "            if convert(key) == 'report':\n",
    "                Dream = convert(value)\n",
    "                HasDream = 1\n",
    "            if convert(key) == 'number':\n",
    "                DreamNumber = convert(value)\n",
    "        \n",
    "        if HasDream == 1:\n",
    "            ID += 1\n",
    "            df = df.append({\n",
    "                \"ID\": ID,\n",
    "                \"W266ID\": W266ID,\n",
    "                \"DreamBankID\": DreamBankID,\n",
    "                \"DreamNumber\": DreamNumber,\n",
    "                \"Name\": Name,\n",
    "                \"Sex\": Sex,\n",
    "                \"Dream\": Dream\n",
    "                }, ignore_index=True)        \n",
    "#     print '\\n'\n",
    "\n",
    "# print df\n",
    "print \"Total Dreams: \" + str(ID)\n",
    "print \"\\n\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Males: ' + str(len(df[df['Sex']=='M']))\n",
    "print 'Females: ' + str(len(df[df['Sex']=='F']))\n",
    "print 'Total: ' + str(len(df[df['Sex']=='M']) + len(df[df['Sex']=='F']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "We want to create a different model for each dreamer (i.e. a classifier identifying one vs all-others for each dreamer). This will allow us to identify the most predictive words in identifying each dreamer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly shuffle dataframe\n",
    "# set seed for consistency while running\n",
    "np.random.seed(0)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "# add 41 flag columns denoting dreamers (one col per dreamer) \n",
    "dreamer_flag = pd.get_dummies(df['W266ID'], prefix='Dreamer')\n",
    "df = pd.concat([df, dreamer_flag], axis=1)\n",
    "\n",
    "# create vocab from all dreams\n",
    "dreams_flat = df['Dream'].values.flatten().tolist()\n",
    "dreams_list = \" \".join(dreams_flat)\n",
    "vocab = list(set(nltk.tokenize.word_tokenize(dreams_list)))\n",
    "\n",
    "def split_data(df, W266ID, train=0.6):        \n",
    "    # column for \"our\" dreamer\n",
    "    dreamer_label = 'Dreamer_' + str(W266ID)\n",
    "\n",
    "    # make 60/40 split of train/test\n",
    "    # test will be evenly split between dev and test in the next step\n",
    "    num_train = int(len(df) * train)\n",
    "    num_test = int(len(df) * (1-train)) \n",
    "\n",
    "    train_data, train_labels = df['Dream'][:num_train], df[dreamer_label][:num_train]\n",
    "    dev_data, dev_labels = df['Dream'][-num_test : -num_test//2], df[dreamer_label][-num_test : -num_test//2] \n",
    "    test_data, test_labels = df['Dream'][-num_test//2:], df[dreamer_label][-num_test//2:]\n",
    "\n",
    "    return train_data, train_labels, dev_data, dev_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for dreamer1 - Alta\n",
    "train_data, train_labels, dev_data, dev_labels, test_data, test_labels = split_data(df, W266ID=1)\n",
    "    \n",
    "# Create a Bag-of-Words Vectorizer\n",
    "vec = CountVectorizer(vocabulary=vocab)\n",
    "vec_bow_train_data = vec.fit_transform(train_data)\n",
    "vec_bow_dev_data = vec.transform(dev_data)  \n",
    "\n",
    "# Create a Tfidf Vectorizer\n",
    "vec_tfidf = TfidfVectorizer(stop_words='english')\n",
    "vec_tfidf_train_data = vec_tfidf.fit_transform(train_data)\n",
    "vec_tfidf_dev_data   = vec_tfidf.transform(dev_data)\n",
    "\n",
    "best_lr_score = 0\n",
    "\n",
    "## Logistic reg\n",
    "for c in (0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 500):\n",
    "    bow_log = LogisticRegression(C = c)\n",
    "    bow_log.fit(vec_bow_train_data, train_labels)\n",
    "    \n",
    "    tfidf_logit_model = LogisticRegression(C=c)\n",
    "    tfidf_logit_model.fit(vec_tfidf_train_data, train_labels)\n",
    "    \n",
    "    f1_bow_lr_score = metrics.f1_score(dev_labels, bow_log.predict(vec_bow_dev_data), average='macro')    \n",
    "    f1_tfidf_lr_score = metrics.f1_score(dev_labels, tfidf_logit_model.predict(vec_tfidf_dev_data), average='macro') \n",
    "\n",
    "    print 'Logistic Reg:\\t C=%3.4f\\t BOW: F1-score=%3.3f\\t TFIDF: F1-score=%3.3f' % (c, f1_bow_lr_score, f1_tfidf_lr_score)\n",
    "\n",
    "    if f1_bow_lr_score > best_lr_score:\n",
    "        best_lr_score = f1_bow_lr_score\n",
    "        best_C = c \n",
    "        vectorizer = 'BOW'\n",
    "        \n",
    "    if f1_tfidf_lr_score > best_lr_score:\n",
    "        best_lr_score = f1_tfidf_lr_score\n",
    "        best_C = c\n",
    "        vectorizer = 'TFIDF'\n",
    "\n",
    "print ''\n",
    "print 'Best model:\\t C=%3.4f\\t vectorizer = %s\\t F1-score=%3.3f' % (best_C, vectorizer, best_lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for dreamer2 - Angie\n",
    "train_data, train_labels, dev_data, dev_labels, test_data, test_labels = split_data(df, W266ID=2)\n",
    "    \n",
    "# Create a Bag-of-Words Vectorizer\n",
    "vec = CountVectorizer(vocabulary=vocab)\n",
    "vec_bow_train_data = vec.fit_transform(train_data)\n",
    "vec_bow_dev_data = vec.transform(dev_data)  \n",
    "\n",
    "# Create a Tfidf Vectorizer\n",
    "vec_tfidf = TfidfVectorizer(stop_words='english')\n",
    "vec_tfidf_train_data = vec_tfidf.fit_transform(train_data)\n",
    "vec_tfidf_dev_data   = vec_tfidf.transform(dev_data)\n",
    "\n",
    "best_lr_score = 0\n",
    "\n",
    "## Logistic reg\n",
    "for c in (0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 500):\n",
    "    bow_log = LogisticRegression(C = c)\n",
    "    bow_log.fit(vec_bow_train_data, train_labels)\n",
    "    \n",
    "    tfidf_logit_model = LogisticRegression(C=c)\n",
    "    tfidf_logit_model.fit(vec_tfidf_train_data, train_labels)\n",
    "    \n",
    "    f1_bow_lr_score = metrics.f1_score(dev_labels, bow_log.predict(vec_bow_dev_data), average='macro')    \n",
    "    f1_tfidf_lr_score = metrics.f1_score(dev_labels, tfidf_logit_model.predict(vec_tfidf_dev_data), average='macro') \n",
    "\n",
    "    print 'Logistic Reg:\\t C=%3.4f\\t BOW: F1-score=%3.3f\\t TFIDF: F1-score=%3.3f' % (c, f1_bow_lr_score, f1_tfidf_lr_score)\n",
    "\n",
    "    if f1_bow_lr_score > best_lr_score:\n",
    "        best_lr_score = f1_bow_lr_score\n",
    "        best_C = c \n",
    "        vectorizer = 'BOW'\n",
    "        \n",
    "    if f1_tfidf_lr_score > best_lr_score:\n",
    "        best_lr_score = f1_tfidf_lr_score\n",
    "        best_C = c\n",
    "        vectorizer = 'TFIDF'\n",
    "\n",
    "print ''\n",
    "print 'Best model:\\t C=%3.4f\\t vectorizer = %s\\t F1-score=%3.3f' % (best_C, vectorizer, best_lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for dreamer3 - Arlie\n",
    "train_data, train_labels, dev_data, dev_labels, test_data, test_labels = split_data(df, W266ID=3)\n",
    "    \n",
    "# Create a Bag-of-Words Vectorizer\n",
    "vec = CountVectorizer(vocabulary=vocab)\n",
    "vec_bow_train_data = vec.fit_transform(train_data)\n",
    "vec_bow_dev_data = vec.transform(dev_data)  \n",
    "\n",
    "# Create a Tfidf Vectorizer\n",
    "vec_tfidf = TfidfVectorizer(stop_words='english')\n",
    "vec_tfidf_train_data = vec_tfidf.fit_transform(train_data)\n",
    "vec_tfidf_dev_data   = vec_tfidf.transform(dev_data)\n",
    "\n",
    "best_lr_score = 0\n",
    "\n",
    "## Logistic reg\n",
    "for c in (0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 500):\n",
    "    bow_log = LogisticRegression(C = c)\n",
    "    bow_log.fit(vec_bow_train_data, train_labels)\n",
    "    \n",
    "    tfidf_logit_model = LogisticRegression(C=c)\n",
    "    tfidf_logit_model.fit(vec_tfidf_train_data, train_labels)\n",
    "    \n",
    "    f1_bow_lr_score = metrics.f1_score(dev_labels, bow_log.predict(vec_bow_dev_data), average='macro')    \n",
    "    f1_tfidf_lr_score = metrics.f1_score(dev_labels, tfidf_logit_model.predict(vec_tfidf_dev_data), average='macro') \n",
    "\n",
    "    print 'Logistic Reg:\\t C=%3.4f\\t BOW: F1-score=%3.3f\\t TFIDF: F1-score=%3.3f' % (c, f1_bow_lr_score, f1_tfidf_lr_score)\n",
    "\n",
    "    if f1_bow_lr_score > best_lr_score:\n",
    "        best_lr_score = f1_bow_lr_score\n",
    "        best_C = c \n",
    "        vectorizer = 'BOW'\n",
    "        \n",
    "    if f1_tfidf_lr_score > best_lr_score:\n",
    "        best_lr_score = f1_tfidf_lr_score\n",
    "        best_C = c\n",
    "        vectorizer = 'TFIDF'\n",
    "\n",
    "print ''\n",
    "print 'Best model:\\t C=%3.4f\\t vectorizer = %s\\t F1-score=%3.3f' % (best_C, vectorizer, best_lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # split data for dreamer1 - Alta\n",
    "# train_data, train_labels, dev_data, dev_labels, test_data, test_labels = split_data(df, W266ID=1)\n",
    "    \n",
    "# # Create a Bag-of-Words Vectorizer\n",
    "# vec = CountVectorizer(vocabulary=vocab)\n",
    "# vec_train_data = vec.fit_transform(train_data)\n",
    "# vec_dev_data = vec.transform(dev_data)  \n",
    "\n",
    "# log = LogisticRegression(C = 100)\n",
    "# log.fit(vec_train_data, train_labels)\n",
    "\n",
    "# test_df = pd.DataFrame('Labels': [dev_labels], 'Prediction': log.predict(vec_dev_data), 'Correct_Pred': dev_labels==log.predict(vec_dev_data))\n",
    "# data = {'Labels': dev_labels, 'Prediction': log.predict(vec_dev_data), 'Correct_Pred': dev_labels==log.predict(vec_dev_data)}\n",
    "# test_df = pd.DataFrame(data)\n",
    "# test_df.head(30)\n",
    "\n",
    "# print confusion_matrix(dev_labels, log.predict(vec_dev_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a model for each dreamer\n",
    "\n",
    "We need to run a separate model for each dreamer. The models will predict if a dream comes from that dreamer or from \"all-others\". Since bag-of-words was working best in the above models, we will continue to use that for our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run Logisitic Regression for each dreamer\n",
    "\n",
    "models = {}\n",
    "\n",
    "for i in range(0,41):\n",
    "    # split data\n",
    "    train_data, train_labels, dev_data, dev_labels, test_data, test_labels = split_data(df, W266ID=i)\n",
    "\n",
    "    # Create a Bag-of-Words Vectorizer\n",
    "    vec = CountVectorizer(vocabulary=vocab)\n",
    "    vec_train_data = vec.fit_transform(train_data)\n",
    "    vec_dev_data = vec.transform(dev_data)  \n",
    "\n",
    "    ## Logistic reg\n",
    "    log = LogisticRegression(C = 100)\n",
    "    log.fit(vec_bow_train_data, train_labels)\n",
    "\n",
    "    # score model\n",
    "    f1_score = metrics.f1_score(dev_labels, log.predict(vec_dev_data), average='macro')\n",
    "    \n",
    "    # find the most-predictive features\n",
    "    ### we're not using the weights currently, but might be useful/interesting later ###    \n",
    "    best_feature_positions = log.coef_.argsort()[0][-5::]\n",
    "    best_feature_weights = log.coef_[0][best_feature_positions.astype(int)]\n",
    "\n",
    "    # get word labels for our features\n",
    "    words = []\n",
    "    for ft in best_feature_positions.astype(int):\n",
    "        words.append(vec.get_feature_names()[ft])\n",
    "    \n",
    "    models[i] = (log, f1_score, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Predictive Words\n",
    "\n",
    "Now that we have a separate model for each dreamer, we can pull out the most predictive words from each model. This shows, for a given dreamer, which words are most predictive of their dreams as opposed to someone else's dream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, (model, score, predictive_words) in models.iteritems():\n",
    "    print 'W266ID='+str(key), '\\tMost Predictive', predictive_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Each Dreamer\n",
    "\n",
    "We can use our models to predict which person a given dream came from. If we take a dream from our test set and run all 41 models on that dream, we will get probabilities of the dream coming from that person. We can then take the highest probability and make that our prediction for who the dream came from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict dreamer for each test dream\n",
    "vec_test_data = vec.transform(test_data)\n",
    "\n",
    "preds = []\n",
    "# for dream in range(len(test_labels)):\n",
    "for dream in range(len(test_labels)):\n",
    "    highest_prob = 0\n",
    "    \n",
    "    # predicted probability of the correct label for each model\n",
    "    for key, (model, score, w) in models.iteritems():\n",
    "        prob_correct =  model.predict_proba(vec_test_data[dream])[0][1]\n",
    "        if prob_correct > highest_prob:\n",
    "            highest_prob = prob_correct\n",
    "            pred = key\n",
    "    \n",
    "    preds.append(pred)\n",
    "    \n",
    "print sum(preds == df['W266ID'][20800:]) / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an 82% success rate on our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"W266ID\"]!=0][['W266ID', 'Name']].sort_values(by= [\"W266ID\"]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreams = list(df['Dream'])\n",
    "\n",
    "# Split the documents into tokens.\n",
    "for idx in range(len(dreams)):\n",
    "    dreams[idx] = dreams[idx].lower()  # Convert to lowercase.\n",
    "    dreams[idx] = nltk.tokenize.word_tokenize(dreams[idx])  # Split into words.\n",
    "    dreams[idx] = nltk.pos_tag(dreams[idx])  # tag with PoS\n",
    "    dreams[idx] = [token for token, tag in dreams[idx] if tag.startswith('N')]   # only keep nouns \n",
    "    \n",
    "# Remove numbers, but not words that contain numbers.\n",
    "dreams = [[token for token in dream if not token.isdigit()] for dream in dreams]\n",
    "\n",
    "# Remove words that are only one or two characters.\n",
    "dreams = [[token for token in dream if len(token) > 2] for dream in dreams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the dreams.\n",
    "lmtzr = WordNetLemmatizer()\n",
    "dreams = [[lmtzr.lemmatize(token) for token in dream] for dream in dreams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the dreams.\n",
    "dictionary = Dictionary(dreams)\n",
    "\n",
    "# Filter out words that occur less than 10 dreams, or more than 60% of the dreams.\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.6)\n",
    "\n",
    "# Vectorize data.\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for dream in dreams]\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of dreams: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BELOW IS FROM: https://markroxor.github.io/gensim/static/notebooks/lda_training_tips.html__\n",
    "\n",
    "__HELPS EXPLAIN THE PARAMETERS__\n",
    "\n",
    "## Training\n",
    "\n",
    "*We are ready to train the LDA model. We will first discuss how to set some of the training parameters.*\n",
    "\n",
    "*First of all, the elephant in the room: how many topics do I need? There is really no easy answer for this, it will depend on both your data and your application. I have used 10 topics here because I wanted to have a few topics that I could interpret and \"label\", and because that turned out to give me reasonably good results. You might not need to interpret all your topics, so you could use a large number of topics, for example 100.*\n",
    "\n",
    "*The `chunksize` controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory. I've set chunksize = 2000, which is more than the amount of documents, so I process all the data in one go. Chunksize can however influence the quality of the model, as discussed in Hoffman and co-authors [2], but the difference was not substantial in this case.*\n",
    "\n",
    "*`passes` controls how often we train the model on the entire corpus. Another word for passes might be \"epochs\". iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of \"passes\" and \"iterations\" high enough.*\n",
    "\n",
    "*I suggest the following way to choose iterations and passes. First, enable logging (as described in many Gensim tutorials), and set eval_every = 1 in LdaModel. When training the model look for a line in the log that looks something like this: *\n",
    "\n",
    "    `2016-06-21 15:40:06,753 - gensim.models.ldamodel - DEBUG - 68/1566 documents converged within 400 iterations`\n",
    "\n",
    "*If you set `passes` = 20 you will see this line 20 times. Make sure that by the final passes, most of the documents have converged. So you want to choose both passes and iterations to be high enough for this to happen.*\n",
    "\n",
    "*We set `alpha = 'auto'` and `eta = 'auto'`. Again this is somewhat technical, but essentially we are automatically learning two parameters in the model that we usually would have to specify explicitly. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 46s\n"
     ]
    }
   ],
   "source": [
    "# Train LDA model.\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 20\n",
    "chunksize = 20000\n",
    "passes = 50\n",
    "iterations = 500\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "# temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "%time model = LdaModel(corpus=corpus, id2word=id2word, chunksize=chunksize, \\\n",
    "                        eta=0.1, iterations=iterations, num_topics=num_topics, \\\n",
    "                       passes=passes, eval_every=eval_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-af725eef856a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtop_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtop_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print('Average topic coherence: %.4f.' % avg_topic_coherence)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\battix\\Anaconda2\\lib\\site-packages\\gensim-3.1.0-py2.7-win-amd64.egg\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36mtop_topics\u001b[1;34m(self, corpus, texts, dictionary, window_size, coherence, topn, processes)\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[0mprocesses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         )\n\u001b[1;32m--> 898\u001b[1;33m         \u001b[0mcoherence_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_coherence_per_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m         \u001b[0mstr_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\battix\\Anaconda2\\lib\\site-packages\\gensim-3.1.0-py2.7-win-amd64.egg\\gensim\\models\\coherencemodel.pyc\u001b[0m in \u001b[0;36mget_coherence_per_topic\u001b[1;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'normalize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoherence\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c_npmi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegmented_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accumulator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maggregate_measures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_coherences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\battix\\Anaconda2\\lib\\site-packages\\gensim-3.1.0-py2.7-win-amd64.egg\\gensim\\topic_coherence\\direct_confirmation_measure.pyc\u001b[0m in \u001b[0;36mlog_conditional_probability\u001b[1;34m(segmented_topics, accumulator, with_std, with_support)\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[0mw_star_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw_star\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mco_occur_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_star\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                 \u001b[0mm_lc_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mco_occur_count\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mEPSILON\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw_star_count\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mm_lc_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "# avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "# print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (1,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (2,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (3,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (4,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (5,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (6,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (7,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (8,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (9,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (10,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (11,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (12,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (13,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (14,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (15,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (16,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (17,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (18,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"'),\n",
       " (19,\n",
       "  u'0.000*\"crutch\" + 0.000*\"governor\" + 0.000*\"fun\" + 0.000*\"error\" + 0.000*\"behavior\" + 0.000*\"match\" + 0.000*\"bikini\" + 0.000*\"pace\" + 0.000*\"rope\" + 0.000*\"ross\"')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape: num_topics x vocabulary_size\n",
    "# print model.get_topics()\n",
    "\n",
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
